{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Projects\\\\Concrete_Prediction\\\\Concrete_Compressive_Strength_Prediction\\\\notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Projects\\\\Concrete_Prediction\\\\Concrete_Compressive_Strength_Prediction'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from concrete_strength_prediction.exception import customexception\n",
    "from concrete_strength_prediction.logger import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_object(file_path, obj):\n",
    "    try:\n",
    "        dir_path = os.path.dirname(file_path)\n",
    "\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "        with open(file_path, \"wb\") as file_obj:\n",
    "            pickle.dump(obj, file_obj)\n",
    "\n",
    "    except Exception as e:\n",
    "        raise customexception(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def load_object(file_path):\n",
    "    try:\n",
    "        with open(file_path,'rb') as file_obj:\n",
    "            return pickle.load(file_obj)\n",
    "    except Exception as e:\n",
    "        logging.info('Exception Occured in load_object function utils')\n",
    "        raise customexception(e,sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataTransformationConfig:\n",
    "    preprocessor_obj_file_path=os.path.join('artifacts','preprocessor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self):\n",
    "        self.data_transformation_config=DataTransformationConfig()\n",
    "\n",
    "        \n",
    "    \n",
    "    def get_data_transformation(self):\n",
    "        \n",
    "        try:\n",
    "            logging.info('Data Transformation initiated')\n",
    "\n",
    "            # Define which columns should be scaled\n",
    "            numerical_columns = ['cement', 'blast_furnace_slag', 'fly_ash', 'water', 'superplasticizer', 'coarse_aggregate', 'fine_aggregate ', 'age']\n",
    "            \n",
    "            \n",
    "            logging.info('Pipeline Initiated')\n",
    "            \n",
    "            \n",
    "\n",
    "            num_pipeline = Pipeline(\n",
    "            steps=[\n",
    "            ('imputer', SimpleImputer(strategy='mean')),  \n",
    "            ('scaler', StandardScaler())])\n",
    "\n",
    "            # Full Pipeline\n",
    "            preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "            ('num', num_pipeline, numerical_columns)])\n",
    "            \n",
    "            return preprocessor\n",
    "            \n",
    "\n",
    "        except Exception as e:\n",
    "            logging.info(\"Exception occured in the initiate_datatransformation\")\n",
    "\n",
    "            raise customexception(e,sys)\n",
    "\n",
    "    def remove_outliers_IQR(self,col,df):\n",
    "        try:\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "            df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "            return df\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.info(\"Problem in Outliers handling code\")\n",
    "            raise CustomException(e,sys)\n",
    "            \n",
    "    \n",
    "    def initialize_data_transformation(self, train_path, test_path):\n",
    "        try:\n",
    "            logging.info(\"Reading train and test data from CSV files\")\n",
    "            train_df = pd.read_csv(train_path)\n",
    "            test_df = pd.read_csv(test_path)\n",
    "\n",
    "            logging.info(\"Read train and test data complete\")\n",
    "            logging.info(f'Train Dataframe Head:\\n{train_df.head().to_string()}')\n",
    "            logging.info(f'Test Dataframe Head:\\n{test_df.head().to_string()}')\n",
    "\n",
    "            numerical_columns = ['cement', 'blast_furnace_slag', 'fly_ash', 'water', 'superplasticizer', 'coarse_aggregate', 'fine_aggregate ', 'age']\n",
    "            \n",
    "            logging.info('Outliers removed in train data')\n",
    "            logging.info(f'train data shape : {train_df.shape}')\n",
    "            for col in numerical_columns:\n",
    "                train_df = self.remove_outliers_IQR(col = col, df = train_df)\n",
    "            logging.info(f'after removed outliers: {train_df.shape}')\n",
    "\n",
    "            logging.info('Outliers removed in test data')\n",
    "            logging.info(f'train data shape : {test_df.shape}')\n",
    "            for col in numerical_columns:\n",
    "                test_df = self.remove_outliers_IQR(col = col, df = test_df)\n",
    "            logging.info(f'after removed outliers: {test_df.shape}')\n",
    "\n",
    "            preprocessing_obj = self.get_data_transformation()\n",
    "\n",
    "            target_column_name = 'concrete_compressive_strength'\n",
    "            drop_columns = [target_column_name]\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "            logging.info(\"Extracting features and target columns\")\n",
    "            # Extract features and target columns\n",
    "            input_feature_train_df = train_df.drop(columns=drop_columns, axis=1)\n",
    "            target_feature_train_df = train_df[target_column_name]\n",
    "\n",
    "            input_feature_test_df = test_df.drop(columns=drop_columns, axis=1)\n",
    "            target_feature_test_df = test_df[target_column_name]\n",
    "\n",
    "            logging.info(\"Read train and test data complete\")\n",
    "            logging.info(f'Train Dataframe Head:\\n{input_feature_train_df.head().to_string()}')\n",
    "            logging.info(f'Test Dataframe Head:\\n{input_feature_test_df.head().to_string()}')\n",
    "\n",
    "\n",
    "            logging.info(\"Applying preprocessing object on training and testing datasets\")\n",
    "            # Apply preprocessing object\n",
    "            input_feature_train_arr = preprocessing_obj.fit_transform(input_feature_train_df)\n",
    "            input_feature_test_arr = preprocessing_obj.transform(input_feature_test_df)\n",
    "\n",
    "            logging.info(\"Combining features and target columns into arrays\")\n",
    "            # Combine features and target columns into arrays\n",
    "            train_arr = np.c_[input_feature_train_arr, np.array(target_feature_train_df)]\n",
    "            test_arr = np.c_[input_feature_test_arr, np.array(target_feature_test_df)]\n",
    "\n",
    "            logging.info(\"Saving preprocessing pickle file\")\n",
    "            # Save preprocessing pickle file\n",
    "            save_object(file_path=self.data_transformation_config.preprocessor_obj_file_path, obj=preprocessing_obj)\n",
    "\n",
    "            logging.info(\"Preprocessing pickle file saved\")\n",
    "\n",
    "            return train_arr, test_arr\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Exception occurred in the initialize_data_transformation: {e}\")\n",
    "            raise customexception(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concrete_strength_prediction.pipelines.training_pipeline import train_data_path,test_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-02 20:55:00,608: INFO: 268314604: Reading train and test data from CSV files]\n",
      "[2024-02-02 20:55:00,636: INFO: 268314604: Read train and test data complete]\n",
      "[2024-02-02 20:55:00,665: INFO: 268314604: Train Dataframe Head:\n",
      "   cement  blast_furnace_slag  fly_ash  water  superplasticizer  coarse_aggregate  fine_aggregate   age  concrete_compressive_strength\n",
      "0   531.3                 0.0      0.0  141.8              28.2             852.1            893.7    3                          41.30\n",
      "1   475.0                 0.0      0.0  228.0               0.0             932.0            594.0    7                          38.60\n",
      "2   277.1                 0.0     97.4  160.6              11.8             973.9            875.6    3                          23.14\n",
      "3   436.0                 0.0      0.0  218.0               0.0             838.4            719.7   28                          23.85\n",
      "4   166.8               250.2      0.0  203.5               0.0             975.6            692.6    7                          15.75]\n",
      "[2024-02-02 20:55:00,698: INFO: 268314604: Test Dataframe Head:\n",
      "   cement  blast_furnace_slag  fly_ash  water  superplasticizer  coarse_aggregate  fine_aggregate   age  concrete_compressive_strength\n",
      "0   152.7               144.7      0.0  178.1               8.0             999.7            822.2   28                          19.01\n",
      "1   122.6               183.9      0.0  203.5               0.0             958.2            800.1   28                          24.29\n",
      "2   153.0               102.0      0.0  192.0               0.0             888.0            943.1   90                          26.32\n",
      "3   480.0                 0.0      0.0  192.0               0.0             936.2            712.2    7                          34.57\n",
      "4   500.1                 0.0      0.0  200.0               3.0            1124.4            613.2   28                          44.13]\n",
      "[2024-02-02 20:55:00,704: INFO: 268314604: Outliers removed in train data]\n",
      "[2024-02-02 20:55:00,707: INFO: 268314604: train data shape : (804, 9)]\n",
      "[2024-02-02 20:55:00,803: INFO: 268314604: after removed outliers: (733, 9)]\n",
      "[2024-02-02 20:55:00,806: INFO: 268314604: Outliers removed in test data]\n",
      "[2024-02-02 20:55:00,810: INFO: 268314604: train data shape : (201, 9)]\n",
      "[2024-02-02 20:55:00,924: INFO: 268314604: after removed outliers: (174, 9)]\n",
      "[2024-02-02 20:55:00,932: INFO: 268314604: Data Transformation initiated]\n",
      "[2024-02-02 20:55:00,939: INFO: 268314604: Pipeline Initiated]\n",
      "[2024-02-02 20:55:00,947: INFO: 268314604: Extracting features and target columns]\n",
      "[2024-02-02 20:55:00,962: INFO: 268314604: Read train and test data complete]\n",
      "[2024-02-02 20:55:00,996: INFO: 268314604: Train Dataframe Head:\n",
      "   cement  blast_furnace_slag  fly_ash  water  superplasticizer  coarse_aggregate  fine_aggregate   age\n",
      "1   475.0                 0.0      0.0  228.0               0.0             932.0            594.0    7\n",
      "2   277.1                 0.0     97.4  160.6              11.8             973.9            875.6    3\n",
      "3   436.0                 0.0      0.0  218.0               0.0             838.4            719.7   28\n",
      "4   166.8               250.2      0.0  203.5               0.0             975.6            692.6    7\n",
      "6   295.7                 0.0     95.6  171.5               8.9             955.1            859.2  100]\n",
      "[2024-02-02 20:55:01,075: INFO: 268314604: Test Dataframe Head:\n",
      "   cement  blast_furnace_slag  fly_ash  water  superplasticizer  coarse_aggregate  fine_aggregate   age\n",
      "0   152.7               144.7      0.0  178.1               8.0             999.7            822.2   28\n",
      "1   122.6               183.9      0.0  203.5               0.0             958.2            800.1   28\n",
      "3   480.0                 0.0      0.0  192.0               0.0             936.2            712.2    7\n",
      "4   500.1                 0.0      0.0  200.0               3.0            1124.4            613.2   28\n",
      "5   212.0               141.3      0.0  203.5               0.0             973.4            750.0   28]\n",
      "[2024-02-02 20:55:01,079: INFO: 268314604: Applying preprocessing object on training and testing datasets]\n",
      "[2024-02-02 20:55:01,127: INFO: 268314604: Combining features and target columns into arrays]\n",
      "[2024-02-02 20:55:01,138: INFO: 268314604: Saving preprocessing pickle file]\n",
      "[2024-02-02 20:55:01,147: INFO: 268314604: Preprocessing pickle file saved]\n"
     ]
    }
   ],
   "source": [
    "data_transformation=DataTransformation()\n",
    "train_arr,test_arr=data_transformation.initialize_data_transformation(train_data_path,test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
